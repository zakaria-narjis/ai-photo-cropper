{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s',pretrained=True)\n",
    "clip_model , preprocess = clip.load('ViT-B/32',device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open('jack.jpg').convert(\"RGB\")\n",
    "crop_results = model(img1)\n",
    "results = crop_results.crop(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_images = torch.stack([preprocess(Image.fromarray(result['im'])) for result in results])\n",
    "search_query = \"jack daniels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_images = torch.tensor(np.stack(preprocessed_images)).cuda()\n",
    "with torch.no_grad(): \n",
    "   images_features = clip_model.encode_image(preprocessed_images)\n",
    "   text_encoded = clip_model.encode_text(clip.tokenize(search_query).to(device)) \n",
    "images_features /= images_features.norm(dim=-1, keepdim=True)\n",
    "text_encoded /= text_encoded.norm(dim=-1, keepdim=True)\n",
    "\n",
    "similarity = text_encoded.cpu().numpy() @ images_features.cpu().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_top(results,similarity_list,N):\n",
    "  clip_results = zip(range(len(similarity_list)), similarity_list)\n",
    "  clip_results = sorted(clip_results, key=lambda x: x[1],reverse= True)\n",
    "  top_images = []\n",
    "  scores=[]\n",
    "  for index,score in clip_results[:N]:\n",
    "    scores.append(score)\n",
    "    top_images.append(results[index]['im'])\n",
    "  return scores,top_images  \n",
    "\n",
    "scores,imgs= similarity_top(results,similarity[0],N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = list(map(lambda x:int(x),results[similarity.argmax()]['box']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(results[similarity.argmax()]['im'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.crop(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del similarity, preprocessed_images, search_query, results,crop_results, img1, images_features,imgs,scores,text_encoded\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
